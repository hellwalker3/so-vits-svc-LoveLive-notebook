{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellwalker3/so-vits-svc-LoveLive-notebook/blob/main/so-vits-svc-LoveLive-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ0pQ8NS8mpr"
      },
      "outputs": [],
      "source": [
        "#0. So-vits-svcで必要なモジュールをインポート \n",
        "#(svc-develop-team/so-vits-svcと同じです。)\n",
        "!pip install --upgrade pip setuptools numpy numba\n",
        "!pip install pyworld praat-parselmouth fairseq tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. huggingface上のプログラムをダウンロード\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/spaces/YazawaSunrise/so-vits-svc-LoveLive"
      ],
      "metadata": {
        "id": "dYe-2EWV8red"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. hubertのモデルをダウンロード\n",
        "!wget https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt -O /content/so-vits-svc-LoveLive/hubert/hubert-soft-0d54a1f4.pt"
      ],
      "metadata": {
        "id": "Es-i3oeV8rhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. プログラムを修正(引数を渡せるようにする。不要なプログラムインポート回避)\n",
        "\n",
        "target_file = \"/content/so-vits-svc-LoveLive/inference_main.py\"\n",
        "inference_main =\"\"\"\n",
        "import argparse\n",
        "import io\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile\n",
        "\n",
        "from inference import infer_tool\n",
        "from inference import slicer\n",
        "from inference.infer_tool import Svc\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "chunks_dict = infer_tool.read_temp(\"inference/chunks_temp.json\")\n",
        "\n",
        "def main(model_path, config_path, clean_names, spk_list, trans, slice_db, wav_format):\n",
        "    svc_model = Svc(model_path, config_path)\n",
        "    infer_tool.mkdir([\"raw\", \"results\"])\n",
        "\n",
        "    infer_tool.fill_a_to_b(trans, clean_names)\n",
        "    for clean_name, tran in zip(clean_names, trans):\n",
        "        raw_audio_path = f\"raw/{clean_name}\"\n",
        "        if \".\" not in raw_audio_path:\n",
        "            raw_audio_path += \".wav\"\n",
        "        infer_tool.format_wav(raw_audio_path)\n",
        "        wav_path = Path(raw_audio_path).with_suffix('.wav')\n",
        "        chunks = slicer.cut(wav_path, db_thresh=slice_db)\n",
        "        audio_data, audio_sr = slicer.chunks2audio(wav_path, chunks)\n",
        "\n",
        "        for spk in spk_list:\n",
        "            audio = []\n",
        "            for (slice_tag, data) in audio_data:\n",
        "                print(f'#=====segment start, {round(len(data) / audio_sr, 3)}s======')\n",
        "                length = int(np.ceil(len(data) / audio_sr * svc_model.target_sample))\n",
        "                raw_path = io.BytesIO()\n",
        "                soundfile.write(raw_path, data, audio_sr, format=\"wav\")\n",
        "                raw_path.seek(0)\n",
        "                if slice_tag:\n",
        "                    print('jump empty segment')\n",
        "                    _audio = np.zeros(length)\n",
        "                else:\n",
        "                    out_audio, out_sr = svc_model.infer(spk, tran, raw_path)\n",
        "                    _audio = out_audio.cpu().numpy()\n",
        "                audio.extend(list(_audio))\n",
        "\n",
        "            res_path = f'./results/{clean_name}_{tran}key_{spk}.{wav_format}'\n",
        "            soundfile.write(res_path, audio, svc_model.target_sample, format=wav_format)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Inference')\n",
        "    parser.add_argument('-m', '--model_path', type=str, required=True, help='path to the trained model')\n",
        "    parser.add_argument('-c', '--config_path', type=str, required=True, help='path to the configuration file')\n",
        "    parser.add_argument('-n', '--clean_names', nargs='+', type=str, required=True, help='list of clean audio file names')\n",
        "    parser.add_argument('-s', '--spk_list', nargs='+', type=str, required=True, help='list of speaker names')\n",
        "    parser.add_argument('-t', '--trans', nargs='+', type=int, required=True, help='list of pitch shift values')\n",
        "    parser.add_argument('-sd', '--slice_db', type=int, default=-40, help='threshold for silence removal')\n",
        "    parser.add_argument('-wf', '--wav_format', type=str, default='flac', help='audio output format')\n",
        "\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    args.clean_names = [args.clean_names] if isinstance(args.clean_names, str) else args.clean_names\n",
        "    args.spk_list = [args.spk_list] if isinstance(args.spk_list, str) else args.spk_list\n",
        "    args.trans = [args.trans] if isinstance(args.trans, int) else args.trans\n",
        "  \n",
        "    main(args.model_path, args.config_path, args.clean_names, args.spk_list, args.trans, args.slice_db, args.wav_format)\n",
        "\"\"\"\n",
        "with open(target_file, 'w') as f:\n",
        "    f.write(inference_main)\n",
        "\n",
        "\n",
        "target_file = '/content/so-vits-svc-LoveLive/inference/infer_tool.py'\n",
        "with open(target_file, 'r') as f:\n",
        "    contents = f.read()\n",
        "\n",
        "# 置換対象の文字列と置換後の文字列を指定する\n",
        "old_str = 'import maad'\n",
        "new_str = '#import maad'\n",
        "# 文字列置換を実行する\n",
        "contents = contents.replace(old_str, new_str)\n",
        "# 上書き保存する\n",
        "with open(target_file, 'w') as f:\n",
        "    f.write(contents)"
      ],
      "metadata": {
        "id": "vfu3xjAe8rja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. ディレクトリ移動\n",
        "%cd /content/so-vits-svc-LoveLive"
      ],
      "metadata": {
        "id": "I4RzCgF08rmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. /content/so-vits-svc-LoveLive/rawフォルダに声のみのwavファイルを配置します。 (例はsample.wav)\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(f\"/content/so-vits-svc-LoveLive/raw/sample.wav\"))"
      ],
      "metadata": {
        "id": "Ptz8C43NFh_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. コマンド実行 \n",
        "#(音楽ファイルのサイズは小さくしないとcuda out of memoryになります。20sは大丈夫でした。長いファイルは適当に分割して統合すると良さそうです。)\n",
        "\n",
        "wav_filename =  \"sample\" #/content/so-vits-svc-LoveLive/rawフォルダ内のwavファイルのファイル名\n",
        "group_name = \"Niji2\" #/content/so-vits-svc-LoveLive/checkpoints内のフォルダ名\n",
        "target_model_file = f\"/content/so-vits-svc-LoveLive/checkpoints/{group_name}/model.pth\" #学習済みモデルのパス\n",
        "config_path = f\"/content/so-vits-svc-LoveLive/checkpoints/{group_name}/config.json\" #configのパス\n",
        "speaker =  \"Setsuna\" #configのspeaker\n",
        "wav_format  = \"wav\" #出力音楽ファイルの拡張子\n",
        "\n",
        "!python inference_main.py -n {wav_filename} -m {target_model_file} -c {config_path} -s {speaker} -t 0 -sd -40 -wf {wav_format} \n",
        "# /content/so-vits-svc-LoveLive/resultsフォルダに出力されます。"
      ],
      "metadata": {
        "id": "mgogGI6i81z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. 再生\n",
        "display(Audio(f\"/content/so-vits-svc-LoveLive/results/{wav_filename}_0key_{speaker}.{wav_format}\", autoplay=True))"
      ],
      "metadata": {
        "id": "arWg3Oud9VgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awYugFzSFS15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}